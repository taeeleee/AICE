{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 시험 개요 및 응시 전략**\n",
        "\n",
        "- **시험 정보**:\n",
        "    - 문항 수: 14문항\n",
        "    - 시험 시간: 90분\n",
        "    - 합격 기준: 80점 이상\n",
        "    - 시험 방식: 온라인 (오픈북 형태)\n",
        "- **오픈북 활용 전략**:\n",
        "    - **공식 사이트만 참조 가능**: 시험 중 모르는 함수나 개념이 있다면 공식 문서(예: Pandas, Scikit-learn, Matplotlib, Seaborn, TensorFlow Keras 공식 문서)를 빠르게 검색하여 활용합니다.\n",
        "    - **탭(Tab) 활용**: 여러 공식 문서를 탭으로 열어두고 필요할 때마다 빠르게 전환하며 정보를 찾습니다.\n",
        "    - **시간 안배**: 검색에 너무 많은 시간을 소요하지 않도록 주의하고, 자주 나오는 함수나 개념은 미리 숙지하는 것이 좋습니다.\n",
        "- **문제 풀이 전략**:\n",
        "    - **문제 유형 파악**: 각 문제가 **회귀(Regression) 문제인지 분류(Classification) 문제인지 빠르게 파악**하는 것이 중요합니다. (주로 모델 성능 평가 지표를 통해 유추 가능)\n",
        "    - **단계별 실행 및 결과 확인**: 코드를 한 번에 다 작성하기보다는, 각 단계별로 실행해보고 중간 결과를 확인하면서 오류를 수정하고 다음 단계로 넘어갑니다. (시험 환경에서 반복 실행 가능)\n",
        "    - **꼼꼼한 문제 확인**: 문제 지시사항을 정확히 이해하고, 저장해야 할 변수명, 출력 형식 등을 놓치지 않도록 주의합니다.\n",
        "    - **최종 제출 확인**: 모든 문항을 완료한 후 최종 제출 버튼을 정확히 누릅니다.\n",
        "    - **셀 생성 금지**: 주어진 셀 내에서만 코드를 작성해야 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "3WvzlSmo5nyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **2. 주요 출제 범위 및 핵심 내용**\n",
        "\n",
        "**AI Modeling Process using Python**\n",
        "```\n",
        "1. 문제정의(회귀,분류)\n",
        "2. 데이터 수집\n",
        "3. 데이터 분석(통계분석, 시각화)\n",
        "4. 데이터 전처리(결측치, 인코딩, 행/열 삭제, 치환, 피처엔지니어링, 스케일링 등)\n",
        "5. 모델학습, 평가 및 시각화\n",
        "```\n",
        "**AICE 시험용**\n",
        "```\n",
        "1.  library import\n",
        "2.  data loading\n",
        "3.  데이터 분석(시각화, 통계분석)\n",
        "4.  데이터 전처리(결측치 처리, 인코딩, 행/열 삭제, 치환, 등)\n",
        "5.  모델 학습 (1) - train/valid split\n",
        "6.  모델 학습 (2) - 스케일링(standard, min-max, robust scaler 등 문제에서 주어짐)\n",
        "7.  모델 학습 (3) - 머신러닝 모델 학습\n",
        "8.  모델 학습 (4) - 머신러닝 모델 평가\n",
        "9.  모델 학습 (5) - 딥러닝 모델 학습\n",
        "10. 모델 학습 (6) - 딥러닝 모델 평가 및 시각화\n",
        "```"
      ],
      "metadata": {
        "id": "ppQrA1wL53uW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **가. EDA (탐색적 데이터 분석)**\n",
        "\n",
        "- **필수 라이브러리**: `pandas`, `numpy`, `matplotlib`, `seaborn` (미리 `import` 하는 습관)\n",
        "    - `import pandas as pd`\n",
        "    - `import numpy as np`\n",
        "    - `import matplotlib.pyplot as plt`\n",
        "    - `import seaborn as sns`\n",
        "    - (참고: `import sklearn as sk`는 일반적이지 않으나, 시험 환경에 따라 나올 수 있음. 보통 `from sklearn... import ...` 형태로 사용)\n",
        "- **데이터 로딩**:\n",
        "    - `pd.read_csv('파일명.csv')`\n",
        "    - `pd.read_json('파일명.json')`\n",
        "- **데이터 구성 확인**:\n",
        "    - `df.head()`: 데이터 앞부분 확인\n",
        "    - `df.tail()`: 데이터 뒷부분 확인\n",
        "    - `df.info()`: 데이터 타입, 결측치 등 기본 정보 확인 (가장 중요!)\n",
        "    - `df.describe()`: 수치형 데이터의 기술 통계량 확인\n",
        "    - `df.shape`: 데이터의 행, 열 개수 확인\n",
        "    - `df.columns`: 컬럼명 확인\n",
        "    - `df.dtypes`: 각 컬럼의 데이터 타입 확인\n",
        "    - `df['컬럼명'].value_counts()`: 범주형 데이터의 고유값 빈도 확인\n",
        "        - `df['컬럼명'].value_counts(normalize=True)`: 비율로 확인\n",
        "- **상관 분석**:\n",
        "    - `df.corr()`: 수치형 컬럼 간의 상관계수 행렬 계산\n",
        "    - `sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')`: 상관계수 히트맵 시각화\n",
        "- **데이터 시각화**: (Matplotlib & Seaborn)\n",
        "    - **라인 플롯**: `plt.plot(x, y)`, `sns.lineplot(data=df, x='col_x', y='col_y')`\n",
        "    - **히스토그램**: `plt.hist(data, bins=20)`, `sns.histplot(data, bins=20, kde=True)` (kde: 커널 밀도 추정 곡선)\n",
        "    - **막대 그래프**: `plt.bar(x, height)`, `sns.barplot(data=df, x='col_x', y='col_y')`\n",
        "    - **카운트 플롯**: `sns.countplot(data=df, x='categorical_col')` (범주형 데이터 빈도 시각화)\n",
        "    - **박스 플롯**: `plt.boxplot(data)`, `sns.boxplot(data=df, x='group_col', y='value_col', hue='subgroup_col')` (이상치 확인)\n",
        "    - **산점도**: `plt.scatter(x, y)`, `sns.scatterplot(data=df, x='col_x', y='col_y')`\n",
        "    - **조인트 플롯**: `sns.jointplot(data=df, x='col_x', y='col_y')` (산점도 + 각 축의 히스토그램/KDE)\n",
        "    - **페어 플롯**: `sns.pairplot(df)` (데이터프레임 내 모든 수치형 변수 쌍 간의 산점도 및 각 변수의 히스토그램/KDE)\n",
        "    - **바이올린 플롯**: `sns.violinplot(data=df, x='group_col', y='value_col', hue='subgroup_col')` (박스 플롯 + KDE)\n",
        "    - **그래프 옵션**: `plt.title()`, `plt.xlabel()`, `plt.ylabel()`, `plt.grid(True)`, `plt.xticks(rotation=45)`, `plt.tight_layout()`, `plt.show()`\n",
        "    - **출제 중요도 및 팁**\n",
        "      * !! **`lineplot`**\n",
        "      * !! **`hisplot`**\n",
        "      * !! **`countplot`**\n",
        "      * !! **`jointplot`**\n",
        "      * **`pairplot`**\n",
        "      * !! **`boxplot`**\n",
        "      * **`violinplot`**\n",
        "      * ! **`heatmap`**\n",
        "      * 마지막에`plt.show`를 꼭 써야!"
      ],
      "metadata": {
        "id": "f44vCeaT6f7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **나. 데이터 전처리**\n",
        "\n",
        "- **결측치 처리**:\n",
        "    - `df.isnull().sum()`: 컬럼별 결측치 개수 확인\n",
        "    - `df.isnull().sum().sum()`: 전체 결측치 개수 확인\n",
        "    - `df.fillna(값 또는 방법)`: 결측치를 특정 값이나 평균/중앙값 등으로 채우기\n",
        "        - `df['컬럼명'].fillna(df['컬럼명'].mean(), inplace=True)`\n",
        "    - `df.dropna(axis=0 또는 1)`: 결측치가 있는 행(0) 또는 열(1) 삭제\n",
        "        - `df.dropna(subset=['컬럼명'], inplace=True)`: 특정 컬럼에 결측치가 있는 행 삭제\n",
        "- **인코딩**:\n",
        "    - **라벨 인코딩 (Label Encoding)**: 범주형 데이터를 0부터 시작하는 정수로 변환. (순서가 의미 있을 때 주로 사용)\n",
        "        - `from sklearn.preprocessing import LabelEncoder`\n",
        "        - `le = LabelEncoder()`\n",
        "        - `df['컬럼명_encoded'] = le.fit_transform(df['컬럼명'])`\n",
        "    - **원-핫 인코딩 (One-Hot Encoding)**: 범주형 데이터를 0과 1로 이루어진 이진 벡터로 변환. (순서가 의미 없을 때 주로 사용)\n",
        "        - `pd.get_dummies(df, columns=['범주형컬럼1', '범주형컬럼2'], drop_first=True, dtype=int)`\n",
        "            - `drop_first=True`: 다중공선성 방지를 위해 첫 번째 카테고리 컬럼 삭제\n",
        "            - `dtype=int` (또는 `float`): 생성된 컬럼의 데이터 타입을 정수/실수로 지정 (기본값은 bool)\n",
        "- **데이터 타입 변환**:\n",
        "    - `df['컬럼명'].astype(새로운타입)` (예: `int`, `float`, `str`)\n",
        "- **행/열 선택 및 삭제**:\n",
        "    - **인덱싱**:\n",
        "        - `df.loc[행조건, 열조건]`: 레이블 기반 인덱싱\n",
        "        - `df.iloc[행숫자, 열숫자]`: 정수 위치 기반 인덱싱\n",
        "    - `df.drop(['삭제할컬럼1', '삭제할컬럼2'], axis=1, inplace=True)`: 열 삭제\n",
        "    - `df.drop(삭제할행_인덱스, axis=0, inplace=True)`: 행 삭제\n",
        "- **중복 데이터 처리**:\n",
        "    - `df.duplicated().sum()`: 중복된 행의 개수 확인\n",
        "    - `df.drop_duplicates(keep='first', inplace=True)`: 중복된 행 제거 (기본값: 첫 번째 값 남김)\n",
        "        - `keep='last'`: 마지막 값 남김\n",
        "        - `keep=False`: 모든 중복 값 제거\n",
        "        - `subset=['특정컬럼']`: 특정 컬럼 기준으로 중복 제거\n",
        "- **데이터프레임 병합**:\n",
        "    - `pd.concat([df1, df2], axis=0)`: 행 기준으로 위아래로 붙임 (기본값)\n",
        "    - `pd.concat([df1, df2], axis=1)`: 열 기준으로 좌우로 붙임\n",
        "    - `pd.merge(left_df, right_df, on='key_col', how='inner')`: SQL의 JOIN과 유사\n",
        "        - `how`: `'left'`, `'right'`, `'outer'`, `'inner'` (기본값)\n",
        "        - `left_on='left_key'`, `right_on='right_key'`: 키 컬럼명이 다를 경우 지정\n",
        "- **데이터 스케일링 (정규화/표준화)**:\n",
        "    - **StandardScaler (표준화)**: 평균 0, 분산 1로 변환.\n",
        "        - `from sklearn.preprocessing import StandardScaler`\n",
        "        - `scaler = StandardScaler()`\n",
        "        - `X_train_scaled = scaler.fit_transform(X_train[수치형컬럼들])`\n",
        "        - `X_valid_scaled = scaler.transform(X_valid[수치형컬럼들])` (훈련 데이터로 `fit`한 스케일러 사용)\n",
        "    - **MinMaxScaler (정규화)**: 데이터를 0과 1 사이의 값으로 변환.\n",
        "        - `from sklearn.preprocessing import MinMaxScaler`\n",
        "        - `scaler = MinMaxScaler()`\n",
        "        - (사용법은 StandardScaler와 유사)\n",
        "    - **RobustScaler**: 중앙값(median)과 사분위 범위(IQR)를 사용하여 스케일링. 이상치에 덜 민감.\n",
        "        - `from sklearn.preprocessing import RobustScaler`\n",
        "        - `scaler = RobustScaler()`\n",
        "        - (사용법은 StandardScaler와 유사)\n",
        "- **이상치 처리 (Boxplot 기반)**:\n",
        "    - `Q1 = df['컬럼명'].quantile(0.25)`\n",
        "    - `Q3 = df['컬럼명'].quantile(0.75)`\n",
        "    - `IQR = Q3 - Q1`\n",
        "    - `lower_fence = Q1 - 1.5 * IQR`\n",
        "    - `upper_fence = Q3 + 1.5 * IQR`\n",
        "    - `df.loc[df['컬럼명'] < lower_fence, '컬럼명'] = lower_fence` (아래쪽 이상치를 하한값으로 대체)\n",
        "    - `df.loc[df['컬럼명'] > upper_fence, '컬럼명'] = upper_fence` (위쪽 이상치를 상한값으로 대체)"
      ],
      "metadata": {
        "id": "P-y22bVP6kEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **다. 머신러닝/딥러닝 모델링**\n",
        "\n",
        "- **X, y 데이터 분리**:\n",
        "    - `X = df.drop('타겟변수컬럼명', axis=1)`\n",
        "    - `y = df['타겟변수컬럼명']`\n",
        "- **훈련/검증 데이터 분리**:\n",
        "    - `from sklearn.model_selection import train_test_split`\n",
        "    - `X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)`\n",
        "        - `test_size`: 검증 데이터 비율 (예: 0.2는 20%)\n",
        "        - `random_state`: 재현성을 위한 시드값\n",
        "        - `stratify=y`: **분류 문제에서 타겟 변수의 클래스 비율을 훈련/검증 데이터셋에 동일하게 유지** (매우 중요!)\n",
        "- **머신러닝 모델 (Scikit-learn)**:\n",
        "    - **의사결정나무 (Decision Tree)**:\n",
        "        - 분류: `from sklearn.tree import DecisionTreeClassifier`\n",
        "        - 회귀: `from sklearn.tree import DecisionTreeRegressor`\n",
        "        - `model = DecisionTreeClassifier(max_depth=5, min_samples_split=3, random_state=120)`\n",
        "    - **랜덤 포레스트 (Random Forest)**:\n",
        "        - 분류: `from sklearn.ensemble import RandomForestClassifier`\n",
        "        - 회귀: `from sklearn.ensemble import RandomForestRegressor`\n",
        "        - `model = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=3, random_state=120)`\n",
        "    - **모델 학습**: `model.fit(X_train_scaled, y_train)`\n",
        "    - **예측**: `y_pred = model.predict(X_valid_scaled)`\n",
        "    - **확률 예측 (분류)**: `y_pred_proba = model.predict_proba(X_valid_scaled)[:, 1]` (주로 이진 분류에서 양성 클래스 확률)\n",
        "- **딥러닝 모델 (TensorFlow Keras)**:\n",
        "    - `import tensorflow as tf`\n",
        "    - `from tensorflow.keras.models import Sequential, load_model`\n",
        "    - `from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization`\n",
        "    - `from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint`\n",
        "    - `from tensorflow.keras.utils import to_categorical` (분류 문제에서 y를 원-핫 인코딩)\n",
        "    - **시드 고정**: `tf.random.set_seed(42)` (재현성)\n",
        "    - **모델 정의 (Sequential API 예시)**:\n",
        "        \n",
        "        ```python\n",
        "        model = Sequential([\n",
        "            Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)), # 입력층\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "            Dense(64, activation='relu'), # 은닉층\n",
        "            BatchNormalization(),\n",
        "            Dropout(0.3),\n",
        "            Dense(1) # 회귀 출력층 (활성화 함수 없음)\n",
        "            # Dense(1, activation='sigmoid') # 이진 분류 출력층\n",
        "            # Dense(num_classes, activation='softmax') # 다중 클래스 분류 출력층\n",
        "        ])\n",
        "        \n",
        "        ```\n",
        "        \n",
        "    - **모델 컴파일**:\n",
        "        - 회귀: `model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])`\n",
        "        - 이진 분류: `model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])`\n",
        "        - 다중 분류 (y가 정수 레이블): `model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`\n",
        "        - 다중 분류 (y가 원-핫 인코딩): `model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])`\n",
        "    - **콜백 함수**:\n",
        "        - `early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)`\n",
        "        - `model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)`\n",
        "    - **모델 학습**: `history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping, model_checkpoint])`\n",
        "    - **예측**:\n",
        "        - 회귀: `y_pred_dl = model.predict(X_valid_scaled)`\n",
        "        - 분류: `y_pred_dl_classes = np.argmax(model.predict(X_valid_scaled), axis=1)` (다중 분류) 또는 `(model.predict(X_valid_scaled) > 0.5).astype(\"int32\")` (이진 분류)"
      ],
      "metadata": {
        "id": "oJPeflf06oB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **라. 모델 성능 평가**\n",
        "\n",
        "- **회귀 모델 평가 지표**: `from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score`\n",
        "    - **MAE (Mean Absolute Error)**: `mean_absolute_error(y_valid, y_pred)` (작을수록 좋음)\n",
        "    - **MSE (Mean Squared Error)**: `mean_squared_error(y_valid, y_pred)` (작을수록 좋음)\n",
        "    - **RMSE (Root Mean Squared Error)**: `np.sqrt(mean_squared_error(y_valid, y_pred))` (작을수록 좋음)\n",
        "    - **R² (결정 계수)**: `r2_score(y_valid, y_pred)` (1에 가까울수록 좋음)\n",
        "- **분류 모델 평가 지표**: `from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve`\n",
        "    - **Accuracy (정확도)**: `accuracy_score(y_valid, y_pred_classes)` (클수록 좋음)\n",
        "    - **Precision (정밀도)**: `precision_score(y_valid, y_pred_classes, average='binary' 또는 'macro' 또는 'weighted')` (클수록 좋음)\n",
        "        - `average='binary'`: 이진 분류 (기본값)\n",
        "        - `average='macro'`: 다중 분류, 각 클래스별 점수 단순 평균\n",
        "        - `average='weighted'`: 다중 분류, 각 클래스별 샘플 수로 가중 평균\n",
        "    - **Recall (재현율)**: `recall_score(y_valid, y_pred_classes, average='binary' 또는 'macro' 또는 'weighted')` (클수록 좋음)\n",
        "    - **F1-Score (F1 점수)**: `f1_score(y_valid, y_pred_classes, average='binary' 또는 'macro' 또는 'weighted')` (클수록 좋음, 정밀도와 재현율의 조화 평균)\n",
        "    - **Confusion Matrix (혼동 행렬)**: `cm = confusion_matrix(y_valid, y_pred_classes)`\n",
        "        - `sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')` 시각화\n",
        "    - **ROC AUC Score**: `roc_auc_score(y_valid, y_pred_proba)` (이진 분류, 1에 가까울수록 좋음)\n",
        "- **딥러닝 모델 학습 과정 시각화**:\n",
        "    \n",
        "    ```python\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy') # 또는 'mae' 등\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy') # 또는 'val_mae' 등\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "    ```\n",
        "    "
      ],
      "metadata": {
        "id": "4JfVpy2u6uTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **3. 추가 팁**\n",
        "\n",
        "- **코드 실행 순서**: 라이브러리 `import`는 코드 맨 위에서 수행하는 것이 원칙입니다. 함수나 클래스를 사용하기 전에 반드시 정의(또는 `import`)되어야 합니다.\n",
        "- **`print()` 함수의 활용**: 여러 결과를 동시에 출력하고 싶을 때 `print()` 함수를 사용하면 좋습니다. Jupyter Notebook 환경에서는 마지막 라인의 결과만 자동으로 출력됩니다. `display(df)`는 데이터프레임을 깔끔하게 출력하는 데 유용합니다.\n",
        "- **Shift + Tab**: Jupyter Notebook에서 함수 괄호 안에서 Shift+Tab을 누르면 해당 함수의 파라미터 정보를 볼 수 있습니다."
      ],
      "metadata": {
        "id": "0fAa2yQG6GsI"
      }
    }
  ]
}